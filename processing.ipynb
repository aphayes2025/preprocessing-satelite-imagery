{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25238\n"
     ]
    }
   ],
   "source": [
    "visited = [] # visited lst\n",
    "final_turb_dict = {}\n",
    "big_direc = os.listdir('/Users/aidanhayes/Desktop/preprocessing-cnn')\n",
    "big_direc.sort() # sorts alphabetically for strings\n",
    "\n",
    "for i in range(len(big_direc)):\n",
    "    folder = big_direc[i]\n",
    "    if '013' in folder:\n",
    "        if folder not in visited:\n",
    "            # getting the paired folders\n",
    "            tif_direc = folder\n",
    "            json_direc = folder + '-json'\n",
    "\n",
    "            # making sure to append so they are considered visited \n",
    "            visited.append(tif_direc)\n",
    "            visited.append(json_direc)\n",
    "            \n",
    "            # code to get lst of tifs, removing csv_file and sorting\n",
    "            lst_tif = os.listdir(tif_direc)\n",
    "            csv_file = [filename for filename in lst_tif if '.csv' in filename]\n",
    "\n",
    "            # if there is no current csv file, continue to next folder \n",
    "            if len(csv_file) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # no index error now \n",
    "                lst_tif.remove(csv_file[0])\n",
    "                lst_tif.sort()\n",
    "            \n",
    "\n",
    "            # convert CSV FILE into dictionary\n",
    "            df = pd.read_csv(folder + '/' + csv_file[0])\n",
    "            turbidity_dict = df.set_index('Unnamed: 0')['turbidity (FNU)'].to_dict()\n",
    "            \n",
    "            \n",
    "            # code to get lst of jsons, and sort\n",
    "            lst_json = os.listdir(json_direc)\n",
    "            lst_json.sort()\n",
    "\n",
    "\n",
    "            lst_tif_checker = [tif.replace('_3B_AnalyticMS_SR_clip.tif', '') for tif in lst_tif]\n",
    "            lst_json_checker = [jsn.replace('_metadata.json', '') for jsn in lst_json]\n",
    "            \n",
    "            for j in range(len(lst_tif_checker)):\n",
    "                tif_image = lst_tif_checker[j]\n",
    "                json_file = lst_json_checker[j]\n",
    "                if tif_image in lst_json_checker:\n",
    "                    modified_tif_image = folder + '/' + tif_image + '_3B_AnalyticMS_SR_clip.tif'\n",
    "                    modified_json_file = folder + '-json' + '/' + json_file + '_metadata.json'\n",
    "                    with open(modified_json_file, 'r') as file:\n",
    "                        # process to extract date time year\n",
    "                        data = json.load(file)\n",
    "                        date = data['properties']['acquired']\n",
    "                        split = date.split(':')\n",
    "                        csv_date = split[0][:10]\n",
    "                      \n",
    "                        # assuming dictionary key is date, value is turbidity \n",
    "                        for date, value in turbidity_dict.items():\n",
    "                            if date == csv_date:\n",
    "                                # print(f'Success found matching dates {csv_date}, and {date}')\n",
    "                                turb_value = value\n",
    "\n",
    "                        # then assign turbidity value to tif image using dict\n",
    "                        key = modified_tif_image\n",
    "                        final_turb_dict[key] = turb_value\n",
    "\n",
    "                        \n",
    "print(len(final_turb_dict))                   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240209_150103_67_24c9_3B_AnalyticMS_SR_clip.tif 20240208_154013_11_2424_metadata.json 763\n",
      "20240214_145812_93_2455_3B_AnalyticMS_SR_clip.tif 20240209_150103_67_24c9_metadata.json 764\n",
      "20240215_154322_63_24a4_3B_AnalyticMS_SR_clip.tif 20240214_145812_93_2455_metadata.json 765\n",
      "20240219_145920_31_24cf_3B_AnalyticMS_SR_clip.tif 20240215_154322_63_24a4_metadata.json 766\n",
      "20240219_145922_47_24cf_3B_AnalyticMS_SR_clip.tif 20240219_145920_31_24cf_metadata.json 767\n",
      "20240220_150151_89_24ce_3B_AnalyticMS_SR_clip.tif 20240219_145922_47_24cf_metadata.json 768\n",
      "20240220_150444_44_2439_3B_AnalyticMS_SR_clip.tif 20240220_150151_89_24ce_metadata.json 769\n",
      "20240221_154401_12_248b_3B_AnalyticMS_SR_clip.tif 20240220_150444_44_2439_metadata.json 770\n",
      "20240221_155741_19_24eb_3B_AnalyticMS_SR_clip.tif 20240221_154401_12_248b_metadata.json 771\n",
      "20240224_150009_26_24c8_3B_AnalyticMS_SR_clip.tif 20240221_155741_19_24eb_metadata.json 772\n",
      "20240225_150644_91_2439_3B_AnalyticMS_SR_clip.tif 20240224_150009_26_24c8_metadata.json 773\n",
      "20240225_150646_85_2439_3B_AnalyticMS_SR_clip.tif 20240225_150644_91_2439_metadata.json 774\n",
      "20240226_150006_79_24c9_3B_AnalyticMS_SR_clip.tif 20240225_150646_85_2439_metadata.json 775\n",
      "20240227_150547_25_2431_3B_AnalyticMS_SR_clip.tif 20240226_150006_79_24c9_metadata.json 776\n",
      "20240301_150411_30_24c9_3B_AnalyticMS_SR_clip.tif 20240227_150547_25_2431_metadata.json 777\n",
      "20240301_150413_43_24c9_3B_AnalyticMS_SR_clip.tif 20240301_150411_30_24c9_metadata.json 778\n",
      "20240308_155438_54_24f4_3B_AnalyticMS_SR_clip.tif 20240301_150413_43_24c9_metadata.json 779\n",
      "20240312_150231_41_2455_3B_AnalyticMS_SR_clip.tif 20240308_155438_54_24f4_metadata.json 780\n",
      "20240313_150133_23_24ab_3B_AnalyticMS_SR_clip.tif 20240312_150231_41_2455_metadata.json 781\n",
      "20240314_150914_35_2427_3B_AnalyticMS_SR_clip.tif 20240313_150133_23_24ab_metadata.json 782\n",
      "20240324_155233_12_24e1_3B_AnalyticMS_SR_clip.tif 20240314_150914_35_2427_metadata.json 783\n",
      "20240324_155352_03_24d2_3B_AnalyticMS_SR_clip.tif 20240324_155233_12_24e1_metadata.json 784\n",
      "20240325_150428_83_24cc_3B_AnalyticMS_SR_clip.tif 20240324_155352_03_24d2_metadata.json 785\n",
      "20240329_154822_14_2461_3B_AnalyticMS_SR_clip.tif 20240325_150428_83_24cc_metadata.json 786\n",
      "20240409_145945_64_24b4_3B_AnalyticMS_SR_clip.tif 20240329_154822_14_2461_metadata.json 787\n",
      "20240416_155524_75_24ee_3B_AnalyticMS_SR_clip.tif 20240409_145945_64_24b4_metadata.json 788\n",
      "20240422_155241_47_24ee_3B_AnalyticMS_SR_clip.tif 20240416_155524_75_24ee_metadata.json 789\n",
      "20240423_154350_64_2416_3B_AnalyticMS_SR_clip.tif 20240422_155241_47_24ee_metadata.json 790\n",
      "20240423_154352_56_2416_3B_AnalyticMS_SR_clip.tif 20240423_154350_64_2416_metadata.json 791\n",
      "20240425_155411_69_24cb_3B_AnalyticMS_SR_clip.tif 20240423_154352_56_2416_metadata.json 792\n",
      "20240427_150154_62_24ba_3B_AnalyticMS_SR_clip.tif 20240425_155411_69_24cb_metadata.json 793\n",
      "20240427_150156_81_24ba_3B_AnalyticMS_SR_clip.tif 20240427_150154_62_24ba_metadata.json 794\n",
      "20240507_154544_24_241c_3B_AnalyticMS_SR_clip.tif 20240427_150156_81_24ba_metadata.json 795\n",
      "20240507_154546_16_241c_3B_AnalyticMS_SR_clip.tif 20240507_154544_24_241c_metadata.json 796\n",
      "20240514_155528_36_249c_3B_AnalyticMS_SR_clip.tif 20240507_154546_16_241c_metadata.json 797\n",
      "20240520_155737_22_24d3_3B_AnalyticMS_SR_clip.tif 20240514_155528_36_249c_metadata.json 798\n",
      "20240520_160002_69_249e_3B_AnalyticMS_SR_clip.tif 20240520_155737_22_24d3_metadata.json 799\n",
      "20240522_150631_70_24af_3B_AnalyticMS_SR_clip.tif 20240520_160002_69_249e_metadata.json 800\n",
      "20240524_155756_01_24eb_3B_AnalyticMS_SR_clip.tif 20240522_150631_70_24af_metadata.json 801\n",
      "20240524_155923_24_2478_3B_AnalyticMS_SR_clip.tif 20240524_155756_01_24eb_metadata.json 802\n",
      "20240524_155925_09_2478_3B_AnalyticMS_SR_clip.tif 20240524_155923_24_2478_metadata.json 803\n",
      "20240525_150945_89_2455_3B_AnalyticMS_SR_clip.tif 20240524_155925_09_2478_metadata.json 804\n",
      "20240525_150947_72_2455_3B_AnalyticMS_SR_clip.tif 20240525_150945_89_2455_metadata.json 805\n",
      "20240601_150629_99_24a1_3B_AnalyticMS_SR_clip.tif 20240525_150947_72_2455_metadata.json 806\n",
      "20240601_151824_21_2439_3B_AnalyticMS_SR_clip.tif 20240601_150629_99_24a1_metadata.json 807\n",
      "20240602_160246_12_2495_3B_AnalyticMS_SR_clip.tif 20240601_151824_21_2439_metadata.json 808\n",
      "20240613_150329_40_24c4_3B_AnalyticMS_SR_clip.tif 20240602_160246_12_2495_metadata.json 809\n",
      "20240615_150600_27_24b5_3B_AnalyticMS_SR_clip.tif 20240613_150329_40_24c4_metadata.json 810\n",
      "20240616_150519_03_24ce_3B_AnalyticMS_SR_clip.tif 20240615_150600_27_24b5_metadata.json 811\n",
      "20240616_155855_91_2475_3B_AnalyticMS_SR_clip.tif 20240616_150519_03_24ce_metadata.json 812\n",
      "20240617_155527_71_24e0_3B_AnalyticMS_SR_clip.tif 20240616_155855_91_2475_metadata.json 813\n",
      "20240617_160024_97_247a_3B_AnalyticMS_SR_clip.tif 20240617_155527_71_24e0_metadata.json 814\n",
      "20240618_150301_78_24b3_3B_AnalyticMS_SR_clip.tif 20240617_160024_97_247a_metadata.json 815\n",
      "20240625_160333_58_2498_3B_AnalyticMS_SR_clip.tif 20240618_150301_78_24b3_metadata.json 816\n",
      "20240702_160159_21_2483_3B_AnalyticMS_SR_clip.tif 20240625_160333_58_2498_metadata.json 817\n",
      "20240720_151937_18_2456_3B_AnalyticMS_SR_clip.tif 20240702_160159_21_2483_metadata.json 818\n",
      "20240720_151938_91_2456_3B_AnalyticMS_SR_clip.tif 20240720_151937_18_2456_metadata.json 819\n",
      "20240728_150537_46_24bf_3B_AnalyticMS_SR_clip.tif 20240720_151938_91_2456_metadata.json 820\n",
      "20240810_150747_93_24c7_3B_AnalyticMS_SR_clip.tif 20240728_150537_46_24bf_metadata.json 821\n",
      "20240823_150732_87_24b0_3B_AnalyticMS_SR_clip.tif 20240810_150747_93_24c7_metadata.json 822\n",
      "20240827_151218_16_24c8_3B_AnalyticMS_SR_clip.tif 20240823_150732_87_24b0_metadata.json 823\n",
      "20240903_155921_53_24f4_3B_AnalyticMS_SR_clip.tif 20240827_151218_16_24c8_metadata.json 824\n",
      "20240904_155719_21_24f3_3B_AnalyticMS_SR_clip.tif 20240903_155921_53_24f4_metadata.json 825\n",
      "20240905_155633_00_24fd_3B_AnalyticMS_SR_clip.tif 20240904_155719_21_24f3_metadata.json 826\n",
      "20240906_155557_17_24f8_3B_AnalyticMS_SR_clip.tif 20240905_155633_00_24fd_metadata.json 827\n",
      "20240911_155550_57_24e5_3B_AnalyticMS_SR_clip.tif 20240906_155557_17_24f8_metadata.json 828\n",
      "20240911_155552_93_24e5_3B_AnalyticMS_SR_clip.tif 20240911_155550_57_24e5_metadata.json 829\n",
      "20240913_151227_74_24cc_3B_AnalyticMS_SR_clip.tif 20240911_155552_93_24e5_metadata.json 830\n",
      "20240913_155736_65_24d7_3B_AnalyticMS_SR_clip.tif 20240913_151227_74_24cc_metadata.json 831\n",
      "20240914_155514_94_24bd_3B_AnalyticMS_SR_clip.tif 20240913_155736_65_24d7_metadata.json 832\n",
      "20240914_155517_28_24bd_3B_AnalyticMS_SR_clip.tif 20240914_155514_94_24bd_metadata.json 833\n",
      "20240915_155515_17_24f6_3B_AnalyticMS_SR_clip.tif 20240914_155517_28_24bd_metadata.json 834\n",
      "20240922_151441_48_24ab_3B_AnalyticMS_SR_clip.tif 20240915_155515_17_24f6_metadata.json 835\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m lst_json[j])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mremove_irregular_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m01362500\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[125], line 14\u001b[0m, in \u001b[0;36mremove_irregular_json\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(lst_tif[-2])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(lst_json[-1])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lst_tif)):\n\u001b[0;32m---> 14\u001b[0m     json_checker \u001b[38;5;241m=\u001b[39m \u001b[43mlst_json\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_metadata.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     tif_checker \u001b[38;5;241m=\u001b[39m lst_tif[i]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_3B_AnalyticMS_SR_clip.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tif_checker \u001b[38;5;241m!=\u001b[39m json_checker:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following function removes the first irregular file in the gauage json file\n",
    "Not perfect \n",
    "'''\n",
    "\n",
    "# def remove_irregular_json(filename):\n",
    "\n",
    "#     lst_tif = os.listdir(filename)\n",
    "#     lst_tif.sort()\n",
    "#     lst_json = os.listdir(f'{filename}-json')\n",
    "#     lst_json.sort()\n",
    "\n",
    "#     # print(lst_tif[-2])\n",
    "#     # print(lst_json[-1])\n",
    "\n",
    "#     for i in range(len(lst_tif)):\n",
    "#         json_checker = lst_json[i].replace('_metadata.json', '')\n",
    "#         tif_checker = lst_tif[i].replace('_3B_AnalyticMS_SR_clip.tif', '')\n",
    "\n",
    "#         if tif_checker != json_checker:\n",
    "#             print(lst_tif[i], lst_json[i], i + 1)\n",
    "#             j = i\n",
    "\n",
    "#     os.remove(filename + \"-json\" + '/' + lst_json[j])\n",
    "#     print('success')\n",
    "\n",
    "# remove_irregular_json('01362500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_direc = 'UVM_gage'\n",
    "json_direc = 'UVM_gage-json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789\n",
      "789\n"
     ]
    }
   ],
   "source": [
    "# code to get lst of tifs, jsons\n",
    "lst_tif = os.listdir(tif_direc)\n",
    "lst_json = os.listdir(json_direc)\n",
    "\n",
    "print(len(lst_tif))\n",
    "print(len(lst_json)) # TODO figure out how to make sure these lists have a json for correct tif\n",
    "\n",
    "if len(lst_tif != lst_json):\n",
    "    print('Not same file setup. Exiting program.')\n",
    "    exit()\n",
    "\n",
    "# # sorting so i of both lsts will refer to same tif-json\n",
    "lst_json.sort()\n",
    "lst_tif.sort()\n",
    "\n",
    "ex_json = json_direc + '/' + lst_json[0] # replace o with i when looping\n",
    "turb_tif_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 9 8\n"
     ]
    }
   ],
   "source": [
    "with open(ex_json, 'r') as file:\n",
    "    # process to extract date time year\n",
    "    data = json.load(file)\n",
    "    date = data['properties']['acquired']\n",
    "    split_date = date.split('-')\n",
    "    year = int(split_date[0])\n",
    "    month = int(split_date[1])\n",
    "    place_day = split_date[2]\n",
    "    day = int(place_day[:2])\n",
    "    \n",
    "    # creating date time object of day image was taken\n",
    "    dt = datetime.datetime(year, month, day)\n",
    "\n",
    "    min = 1000\n",
    "    turb_value = 0\n",
    "\n",
    "    # assuming dictionary key is date, value is turbidity \n",
    "    for other_dt, value in dict.items():\n",
    "        curr_min = dt - other_dt\n",
    "        if curr_min < min:\n",
    "            min = curr_min\n",
    "            turb_value = value\n",
    "\n",
    "    # then assign turbidity value to tif image using dict\n",
    "    key = tif_direc + '/' + lst_tif[0] # replace 0 with i \n",
    "    turb_tif_dict[key] = turb_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(turb_tif_dic)\n",
    "df.to_csv('turbidity-tif.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tifs(directory):\n",
    "    # Count total number of tifs in directory\n",
    "    total_tifs = 0\n",
    "\n",
    "    # Define the expected file size in bytes (1 KB = 1024 bytes)\n",
    "    expected_size = 30 * 1024 # 38.5 KB in bytes\n",
    "    # List to store valid file paths\n",
    "    valid_tif_files = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # update count\n",
    "            total_tifs += 1\n",
    "            # Get the file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            # Get the file size in bytes\n",
    "            file_size = os.path.getsize(file_path)\n",
    "        \n",
    "            # Filter by the expected size\n",
    "            if file_size >= expected_size:\n",
    "                valid_tif_files.append(file_path)\n",
    "                valid_proportion = round(len(valid_tif_files) / total_tifs, 3)\n",
    "\n",
    "    print(f'Total proportion of .tif files that are valid: {valid_proportion}')\n",
    "\n",
    "    return valid_tif_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
